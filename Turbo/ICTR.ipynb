{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab3477d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting sagemaker==1.72.0\n",
      "  Downloading sagemaker-1.72.0.tar.gz (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.3/297.3 KB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: smdebug in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (1.0.12)\n",
      "Requirement already satisfied: boto3>=1.14.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker==1.72.0) (1.24.96)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker==1.72.0) (1.20.3)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker==1.72.0) (3.19.1)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker==1.72.0) (1.5.3)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker==1.72.0) (0.1.5)\n",
      "Collecting smdebug-rulesconfig==0.1.4\n",
      "  Downloading smdebug_rulesconfig-0.1.4-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker==1.72.0) (4.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker==1.72.0) (21.3)\n",
      "Requirement already satisfied: pyinstrument==3.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from smdebug) (3.4.2)\n",
      "Requirement already satisfied: pyinstrument-cext>=0.2.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pyinstrument==3.4.2->smdebug) (0.2.4)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3>=1.14.12->sagemaker==1.72.0) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3>=1.14.12->sagemaker==1.72.0) (0.6.0)\n",
      "Collecting botocore<1.28.0,>=1.27.96\n",
      "  Using cached botocore-1.27.96-py3-none-any.whl (9.3 MB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from importlib-metadata>=1.4.0->sagemaker==1.72.0) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from packaging>=20.0->sagemaker==1.72.0) (3.0.6)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from protobuf3-to-dict>=0.1.5->sagemaker==1.72.0) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.96->boto3>=1.14.12->sagemaker==1.72.0) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.96->boto3>=1.14.12->sagemaker==1.72.0) (1.26.8)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-1.72.0-py2.py3-none-any.whl size=386379 sha256=cd1dd37e07efb4cf5f94b4509106502170bcc461aef2880d91bbab82a8cd0b7f\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/86/0e/1f/7c255f46c88da77dc4d0145188d39efda49e7e69fa9d320edf\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: smdebug-rulesconfig, botocore, sagemaker\n",
      "  Attempting uninstall: smdebug-rulesconfig\n",
      "    Found existing installation: smdebug-rulesconfig 1.0.1\n",
      "    Uninstalling smdebug-rulesconfig-1.0.1:\n",
      "      Successfully uninstalled smdebug-rulesconfig-1.0.1\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.24.19\n",
      "    Uninstalling botocore-1.24.19:\n",
      "      Successfully uninstalled botocore-1.24.19\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.113.0\n",
      "    Uninstalling sagemaker-2.113.0:\n",
      "      Successfully uninstalled sagemaker-2.113.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.0.1 requires botocore<1.22.9,>=1.22.8, but you have botocore 1.27.96 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed botocore-1.27.96 sagemaker-1.72.0 smdebug-rulesconfig-0.1.4\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install \"sagemaker==1.72.0\" smdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61bf19f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.72.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b80c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mFROM\u001b[39;49;00m \u001b[33mpython3\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mRUN\u001b[39;49;00m pip install -r requirements.txt\n",
      "\n",
      "\u001b[34mCOPY\u001b[39;49;00m ictr.py /opt/ml/code/ictr.py\n",
      "\n",
      "\u001b[34mENV\u001b[39;49;00m SAGEMAKER_PROGRAM ictr.py\n"
     ]
    }
   ],
   "source": [
    "! pygmentize docker/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83219146",
   "metadata": {},
   "source": [
    "# Prepare the training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91cabb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m array, zeros, ones, identity, argmax, copy, matmul, outer, arange, delete, argwhere\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mrandom\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m choice\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlinalg\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m inv\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mscipy\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mstats\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m invgamma, multivariate_normal, dirichlet, multinomial\n",
      "\u001b[37m# https://github.com/irec-org/irec/blob/master/irec/recommendation/agents/value_functions/ictr.py\u001b[39;49;00m\n",
      "\u001b[37m# https://github.com/lda-project/lda/blob/develop/lda/_lda.pyx\u001b[39;49;00m\n",
      "\u001b[37m# https://github.com/TaskeHAMANO/OnlineLDA_ParticleFilter/blob/efe5cc88d100fa6d5c2cfbc03593721548eced83/learn.c\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mICTR3\u001b[39;49;00m:\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, n_users: \u001b[36mint\u001b[39;49;00m, n_items: \u001b[36mint\u001b[39;49;00m, n_lat: \u001b[36mint\u001b[39;49;00m, n_particles: \u001b[36mint\u001b[39;49;00m, time_buckets):\n",
      "        \u001b[36mself\u001b[39;49;00m.n_users = n_users\n",
      "        \u001b[36mself\u001b[39;49;00m.n_items = n_items\n",
      "        \u001b[36mself\u001b[39;49;00m.n_lat = n_lat\n",
      "        \u001b[36mself\u001b[39;49;00m.n_particles = n_particles\n",
      "\n",
      "        \u001b[36mself\u001b[39;49;00m.eta = [copy(\u001b[34m100\u001b[39;49;00m * ones((n_lat, n_items))) \u001b[34mfor\u001b[39;49;00m _ \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(n_particles)]\n",
      "        \u001b[36mself\u001b[39;49;00m.lambda_ = [copy(\u001b[34m100\u001b[39;49;00m * ones(n_lat)) \u001b[34mfor\u001b[39;49;00m _ \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(n_particles)]\n",
      "        \u001b[36mself\u001b[39;49;00m.mu = [copy(zeros((n_items, n_lat))) \u001b[34mfor\u001b[39;49;00m _ \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(n_particles)]\n",
      "        \u001b[36mself\u001b[39;49;00m.Sigma = [[copy(identity(n_lat)) \u001b[34mfor\u001b[39;49;00m _i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(n_users)] \u001b[34mfor\u001b[39;49;00m _j \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(n_particles)]\n",
      "        \u001b[36mself\u001b[39;49;00m.Phi = [copy(dirichlet(ones(n_items)).rvs(size=n_lat)) \u001b[34mfor\u001b[39;49;00m _ \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(n_particles)]\n",
      "\n",
      "        \u001b[36mself\u001b[39;49;00m.alpha = [\u001b[34m1.\u001b[39;49;00m] * n_particles\n",
      "        \u001b[36mself\u001b[39;49;00m.beta = [\u001b[34m1.\u001b[39;49;00m] * n_particles\n",
      "        \u001b[36mself\u001b[39;49;00m.alpha_n = [[\u001b[34m1.\u001b[39;49;00m] * n_items] * n_particles\n",
      "        \u001b[36mself\u001b[39;49;00m.beta_n = [[\u001b[34m1.\u001b[39;49;00m] * n_items] * n_particles\n",
      "        \u001b[36mself\u001b[39;49;00m.sigma_2 = [[\u001b[34m1.\u001b[39;49;00m] * n_items] * n_particles\n",
      "        \u001b[37m# self.sigma_2 = [copy(invgamma(1., 1.).rvs(size=n_items)) for _ in range(n_particles)]\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.q = [\n",
      "                    [\n",
      "                        copy(multivariate_normal(\u001b[36mself\u001b[39;49;00m.mu[i][j], \u001b[36mself\u001b[39;49;00m.sigma_2[i][j] * \u001b[36mself\u001b[39;49;00m.Sigma[i][j]).rvs())\n",
      "                        \u001b[34mfor\u001b[39;49;00m j \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(n_items)\n",
      "                    ]\n",
      "                    \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(n_particles)\n",
      "                 ]\n",
      "        \u001b[36mself\u001b[39;49;00m.p = [copy(dirichlet(ones(n_lat)).rvs(size=n_users)) \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(n_particles)]\n",
      "\n",
      "        \u001b[37m# eligible items\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.eligible_items = [copy(arange(n_items)) \u001b[34mfor\u001b[39;49;00m _ \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(n_users)]\n",
      "\n",
      "        \u001b[36mself\u001b[39;49;00m.rewards_log = [\u001b[34m0\u001b[39;49;00m] * time_buckets  \u001b[37m# average reward per bucket\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.a = [\u001b[34m1\u001b[39;49;00m] * time_buckets  \u001b[37m# number of impression per bucket\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.trace = []  \u001b[37m# average reward trace\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.arm_trace = []  \u001b[37m# trace of arm recommendations\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.recommended_arm = \u001b[34mNone\u001b[39;49;00m  \u001b[37m# use to print recommended arm\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mselect_arm\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, user_id):\n",
      "        \u001b[37m# choose arm\u001b[39;49;00m\n",
      "        r = []\n",
      "        \u001b[34mfor\u001b[39;49;00m n \u001b[35min\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.eligible_items[user_id]:\n",
      "            r.append(\u001b[36mself\u001b[39;49;00m.eval(user_id, n))\n",
      "        \u001b[37m# choose arm\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.recommended_arm = \u001b[36mself\u001b[39;49;00m.eligible_items[user_id][argmax(r)]\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.recommended_arm\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32meval\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, user_id, item_id):\n",
      "        r = []\n",
      "        \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.n_particles):\n",
      "            \u001b[37m# get user, item latent vectors\u001b[39;49;00m\n",
      "            p = \u001b[36mself\u001b[39;49;00m.p[i][user_id]\n",
      "            q = \u001b[36mself\u001b[39;49;00m.q[i][item_id]\n",
      "            \u001b[37m# predict ith reward\u001b[39;49;00m\n",
      "            r.append((p * q).sum())\n",
      "        \u001b[37m# return average reward\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36msum\u001b[39;49;00m(r) / \u001b[36mlen\u001b[39;49;00m(r)\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mget_weights\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, user_id, n, reward):\n",
      "        weights = []\n",
      "        \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.n_particles):\n",
      "            \u001b[37m# expected later user vector\u001b[39;49;00m\n",
      "            p_expected = \u001b[36mself\u001b[39;49;00m.lambda_[i] / \u001b[36msum\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.lambda_[i])\n",
      "            \u001b[37m# expected latent ite vector\u001b[39;49;00m\n",
      "            phi_expected = \u001b[36mself\u001b[39;49;00m.eta[i][:, n] / \u001b[36msum\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.eta[i][:, n])\n",
      "            \u001b[37m# compute probability density of observed reward vs predicted reward\u001b[39;49;00m\n",
      "            norm_val = multivariate_normal(\n",
      "                (\u001b[36mself\u001b[39;49;00m.p[i][user_id] * \u001b[36mself\u001b[39;49;00m.q[i][n]).sum(), \u001b[36mself\u001b[39;49;00m.sigma_2[i][n]).pdf(reward)\n",
      "            weights.append(\u001b[36msum\u001b[39;49;00m(norm_val * p_expected * phi_expected))\n",
      "        \u001b[37m# normalize\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m array(weights) / \u001b[36msum\u001b[39;49;00m(weights)\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mresample_particles\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, weights, user_id, n):\n",
      "        samples = choice(\u001b[36mself\u001b[39;49;00m.n_particles, size=\u001b[36mself\u001b[39;49;00m.n_particles, p=weights)\n",
      "        \u001b[34mfor\u001b[39;49;00m i, j \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(samples):\n",
      "            \u001b[36mself\u001b[39;49;00m.eta[i][:, n] = copy(\u001b[36mself\u001b[39;49;00m.eta[j][:, n])\n",
      "            \u001b[36mself\u001b[39;49;00m.lambda_[i] = copy(\u001b[36mself\u001b[39;49;00m.lambda_[j])\n",
      "            \u001b[36mself\u001b[39;49;00m.mu[i][n] = copy(\u001b[36mself\u001b[39;49;00m.mu[j][n])\n",
      "            \u001b[36mself\u001b[39;49;00m.Sigma[i][n] = copy(\u001b[36mself\u001b[39;49;00m.Sigma[j][n])\n",
      "            \u001b[37m# self.sigma_2[i][n] = copy(self.sigma_2[j][n])\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.q[i][n] = copy(\u001b[36mself\u001b[39;49;00m.q[j][n])\n",
      "            \u001b[36mself\u001b[39;49;00m.p[i][user_id] = copy(\u001b[36mself\u001b[39;49;00m.p[j][user_id])\n",
      "            \u001b[36mself\u001b[39;49;00m.Phi[i][:, n] = copy(\u001b[36mself\u001b[39;49;00m.Phi[j][:, n])\n",
      "            \u001b[36mself\u001b[39;49;00m.alpha[i] = copy(\u001b[36mself\u001b[39;49;00m.alpha[j])\n",
      "            \u001b[36mself\u001b[39;49;00m.beta[i] = copy(\u001b[36mself\u001b[39;49;00m.beta[j])\n",
      "            \u001b[36mself\u001b[39;49;00m.alpha_n[i][n] = copy(\u001b[36mself\u001b[39;49;00m.alpha_n[j][n])\n",
      "            \u001b[36mself\u001b[39;49;00m.beta_n[i][n] = copy(\u001b[36mself\u001b[39;49;00m.beta_n[j][n])\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32msample_topic\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, i, user_id, n, reward):\n",
      "        \u001b[37m# draw random topic\u001b[39;49;00m\n",
      "        z = argmax(multinomial(\u001b[34m1\u001b[39;49;00m, [\u001b[34m1\u001b[39;49;00m / \u001b[36mself\u001b[39;49;00m.n_lat] * \u001b[36mself\u001b[39;49;00m.n_lat).rvs())\n",
      "\n",
      "        \u001b[37m# copy variables\u001b[39;49;00m\n",
      "        lmbda = copy(\u001b[36mself\u001b[39;49;00m.lambda_[i])\n",
      "        eta = copy(\u001b[36mself\u001b[39;49;00m.eta[i])\n",
      "\n",
      "        \u001b[37m# update copies\u001b[39;49;00m\n",
      "        lmbda[z] += reward\n",
      "        eta[z, n] += reward\n",
      "\n",
      "        \u001b[37m# get expected p_m and Phi_n\u001b[39;49;00m\n",
      "        p = lmbda / \u001b[36msum\u001b[39;49;00m(lmbda)\n",
      "        phi = eta[:, n] / \u001b[36msum\u001b[39;49;00m(eta[:, n])\n",
      "\n",
      "        \u001b[37m# get expected p_m and Phi_n\u001b[39;49;00m\n",
      "        \u001b[37m# p = self.lambda_[i] / sum(self.lambda_[i])\u001b[39;49;00m\n",
      "        \u001b[37m# phi = self.eta[i][:, n] / sum(self.eta[i][:, n])\u001b[39;49;00m\n",
      "\n",
      "        \u001b[37m# draw latent topic from posterior\u001b[39;49;00m\n",
      "        z = argmax(multinomial(\u001b[34m1\u001b[39;49;00m, p * phi).rvs())\n",
      "\n",
      "        \u001b[37m# update parameters\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.lambda_[i][z] += reward  \u001b[37m# update\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.eta[i][z, n] += reward  \u001b[37m# update\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m z\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mupdate_parameters\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, i, user_id, n, z, reward):\n",
      "        \u001b[37m# get user latent preference vector\u001b[39;49;00m\n",
      "        p = copy(\u001b[36mself\u001b[39;49;00m.p[i][user_id])\n",
      "\n",
      "        \u001b[37m# update covariance\u001b[39;49;00m\n",
      "        old_cov = copy(\u001b[36mself\u001b[39;49;00m.Sigma[i][n])\n",
      "        new_cov = inv(inv(old_cov) + outer(p, p))  \u001b[37m# item updated covariance\u001b[39;49;00m\n",
      "\n",
      "        \u001b[37m# update mean for latent item distribution\u001b[39;49;00m\n",
      "        mu = copy(\u001b[36mself\u001b[39;49;00m.mu[i][n])\n",
      "        new_mu = matmul(new_cov, matmul(inv(old_cov), mu) + p * reward)\n",
      "\n",
      "        \u001b[37m# update inverse gamma hyper-parameters\u001b[39;49;00m\n",
      "        d_old = matmul(matmul(inv(old_cov), mu), mu)\n",
      "        d_new = matmul(matmul(inv(new_cov), new_mu), new_mu)\n",
      "\n",
      "        \u001b[37m# perform update\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.Sigma[i][n] = new_cov\n",
      "        \u001b[36mself\u001b[39;49;00m.mu[i][n] = new_mu\n",
      "        \u001b[36mself\u001b[39;49;00m.alpha[i] += \u001b[34m0.5\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.beta[i] += \u001b[34m0.5\u001b[39;49;00m * (d_old + reward ** \u001b[34m2\u001b[39;49;00m - d_new)\n",
      "        \u001b[36mself\u001b[39;49;00m.alpha_n[i][n] += \u001b[34m0.5\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.beta_n[i][n] += \u001b[34m0.5\u001b[39;49;00m * (d_old + reward ** \u001b[34m2\u001b[39;49;00m - d_new)\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32msample_random_variables\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, i, user_id, n, z):\n",
      "        \u001b[37m# draw variance of the noise for reward prediction\u001b[39;49;00m\n",
      "        \u001b[37m# self.sigma_2[i][n] = invgamma(self.alpha[i], 1/self.beta[i]).rvs()\u001b[39;49;00m\n",
      "        \u001b[37m# draw latent item vector\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.q[i][n] = multivariate_normal(\u001b[36mself\u001b[39;49;00m.mu[i][n], \u001b[36mself\u001b[39;49;00m.sigma_2[i][n] * \u001b[36mself\u001b[39;49;00m.Sigma[i][n]).rvs()\n",
      "        \u001b[37m# draw latent user vector\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.p[i][user_id] = dirichlet(\u001b[36mself\u001b[39;49;00m.lambda_[i]).rvs()\n",
      "        \u001b[37m# draw item mixture corresponding to preference k\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.Phi[i][z] = dirichlet(\u001b[36mself\u001b[39;49;00m.eta[i][z]).rvs()\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32msample\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, user_id):\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m        Stochastically sample user and item latent vectors to encourage replayer exploration\u001b[39;49;00m\n",
      "\u001b[33m        :param user_id:\u001b[39;49;00m\n",
      "\u001b[33m        :return:\u001b[39;49;00m\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.n_particles):\n",
      "            n = choice(\u001b[36mrange\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.n_items))\n",
      "            \u001b[37m# self.sigma_2[i][n] = invgamma(self.alpha[i], 1 / self.beta[i]).rvs()\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.q[i][n] = multivariate_normal(\u001b[36mself\u001b[39;49;00m.mu[i][n], \u001b[36mself\u001b[39;49;00m.sigma_2[i][n] * \u001b[36mself\u001b[39;49;00m.Sigma[i][n]).rvs()\n",
      "            \u001b[36mself\u001b[39;49;00m.p[i][user_id] = dirichlet(\u001b[36mself\u001b[39;49;00m.lambda_[i]).rvs()\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mupdate\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, user_id, n, reward):\n",
      "        \u001b[37m# get particle {m, n(t)} weights\u001b[39;49;00m\n",
      "        weights = \u001b[36mself\u001b[39;49;00m.get_weights(user_id, n, reward)\n",
      "        \u001b[37m# resample particles\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.resample_particles(weights, user_id, n)\n",
      "        \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.n_particles):\n",
      "            \u001b[37m# sample z from posterior\u001b[39;49;00m\n",
      "            z = \u001b[36mself\u001b[39;49;00m.sample_topic(i, user_id, n, reward)\n",
      "            \u001b[37m# update statistics\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.update_parameters(i, user_id, n, z, reward)\n",
      "            \u001b[37m# sample\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.sample_random_variables(i, user_id, n, z)\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mevaluate_policy\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, user_id, item_id, reward, t):\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m        Replayer method of evaluation\u001b[39;49;00m\n",
      "\u001b[33m        :param user_id: user index\u001b[39;49;00m\n",
      "\u001b[33m        :param item_id: item index, required for replayer method\u001b[39;49;00m\n",
      "\u001b[33m        :param reward: observed reward at time t\u001b[39;49;00m\n",
      "\u001b[33m        :param t: time index\u001b[39;49;00m\n",
      "\u001b[33m        :return:\u001b[39;49;00m\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\n",
      "        \u001b[37m# check if there are any items left to recommend\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.eligible_items[user_id].size > \u001b[34m0\u001b[39;49;00m:\n",
      "            \u001b[37m# if yes, select arm\u001b[39;49;00m\n",
      "            n = \u001b[36mself\u001b[39;49;00m.select_arm(user_id)\n",
      "            \u001b[34mif\u001b[39;49;00m n == item_id:\n",
      "                \u001b[37m# update parameter and states\u001b[39;49;00m\n",
      "                \u001b[36mself\u001b[39;49;00m.update(user_id, n, reward)\n",
      "                \u001b[37m# update average reward log for time bucket t\u001b[39;49;00m\n",
      "                \u001b[36mself\u001b[39;49;00m.rewards_log[t] = \u001b[36mself\u001b[39;49;00m.rewards_log[t] + (\u001b[34m1\u001b[39;49;00m / \u001b[36mself\u001b[39;49;00m.a[t]) * (reward - \u001b[36mself\u001b[39;49;00m.rewards_log[t])\n",
      "                \u001b[37m# update impression count for time bucket t\u001b[39;49;00m\n",
      "                \u001b[36mself\u001b[39;49;00m.a[t] += \u001b[34m1\u001b[39;49;00m\n",
      "                \u001b[37m# remove item from eligibility\u001b[39;49;00m\n",
      "                n_loc = argwhere(\u001b[36mself\u001b[39;49;00m.eligible_items[user_id] == n)\n",
      "                \u001b[36mself\u001b[39;49;00m.eligible_items[user_id] = delete(\u001b[36mself\u001b[39;49;00m.eligible_items[user_id], n_loc)\n",
      "                \u001b[37m# append trace\u001b[39;49;00m\n",
      "                \u001b[36mself\u001b[39;49;00m.trace.append(\u001b[36mself\u001b[39;49;00m.rewards_log[t])\n",
      "                \u001b[36mself\u001b[39;49;00m.arm_trace.append(n)\n",
      "            \u001b[34melse\u001b[39;49;00m:\n",
      "                \u001b[36mself\u001b[39;49;00m.sample(user_id)\n",
      "        \u001b[34melse\u001b[39;49;00m:\n",
      "            \u001b[36mself\u001b[39;49;00m.recommended_arm = \u001b[34mNone\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mreplay\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, ratings):\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m        Run experiment on dataset using replayer method\u001b[39;49;00m\n",
      "\u001b[33m        :param ratings: dataset [user_id, item_id, rating and time bucket]\u001b[39;49;00m\n",
      "\u001b[33m        :return:\u001b[39;49;00m\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\n",
      "        \u001b[37m# run experiment\u001b[39;49;00m\n",
      "        i = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m user_id, item_id, rating, t \u001b[35min\u001b[39;49;00m ratings.to_numpy():\n",
      "            \u001b[36mself\u001b[39;49;00m.evaluate_policy(user_id=\u001b[36mint\u001b[39;49;00m(user_id), item_id=\u001b[36mint\u001b[39;49;00m(item_id), reward=rating, t=\u001b[36mint\u001b[39;49;00m(t))\n",
      "            results, impressions = \u001b[36mself\u001b[39;49;00m.get_results()\n",
      "            \u001b[36mprint\u001b[39;49;00m(\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mProgress\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mround\u001b[39;49;00m(i / \u001b[36mlen\u001b[39;49;00m(ratings), \u001b[34m3\u001b[39;49;00m),\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mTime Bucket:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mint\u001b[39;49;00m(t),\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mImpressions:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, impressions[\u001b[36mint\u001b[39;49;00m(t)] - \u001b[34m1\u001b[39;49;00m,\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mUser ID:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mint\u001b[39;49;00m(user_id),\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mSelected Arm:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mself\u001b[39;49;00m.recommended_arm,\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mAverage Rating:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, results[\u001b[36mint\u001b[39;49;00m(t)])\n",
      "            i += \u001b[34m1\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mget_results\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m        Get average reward and impression log\u001b[39;49;00m\n",
      "\u001b[33m        :return: average rating at time t\u001b[39;49;00m\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.rewards_log, \u001b[36mself\u001b[39;49;00m.a\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mget_trace\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m        Return trace\u001b[39;49;00m\n",
      "\u001b[33m        :return:\u001b[39;49;00m\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.trace, \u001b[36mself\u001b[39;49;00m.arm_trace\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "    \u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mdatetime\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m date\n",
      "\n",
      "    \u001b[37m# get ratings data\u001b[39;49;00m\n",
      "    ratings = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33mdatasets/MovieLens10M_ratings.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    ratings = ratings[[\u001b[33m'\u001b[39;49;00m\u001b[33muser_id\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mitem_id\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mrating2\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mtime_bucket\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]]\n",
      "\n",
      "    \u001b[37m# get model params from data\u001b[39;49;00m\n",
      "    T = ratings.time_bucket.nunique()  \u001b[37m# get number of unique time buckets\u001b[39;49;00m\n",
      "    \u001b[37m# get number of users, items\u001b[39;49;00m\n",
      "    n_users = ratings.user_id.nunique()  \u001b[37m# number of users\u001b[39;49;00m\n",
      "    n_items = ratings.item_id.nunique()  \u001b[37m# number of items\u001b[39;49;00m\n",
      "\n",
      "    \u001b[37m# initialize model\u001b[39;49;00m\n",
      "    B = \u001b[34m10\u001b[39;49;00m  \u001b[37m# number of particles\u001b[39;49;00m\n",
      "    K = \u001b[34m3\u001b[39;49;00m  \u001b[37m# latent parameter dimension\u001b[39;49;00m\n",
      "    model = ICTR3(n_users=n_users, n_items=n_items, n_lat=K, n_particles=B, time_buckets=T)\n",
      "\n",
      "    \u001b[37m# run experiment\u001b[39;49;00m\n",
      "    model.replay(ratings)\n",
      "\n",
      "    \u001b[37m# get results\u001b[39;49;00m\n",
      "    avg_rating, impressions = model.get_results()\n",
      "    reward_trace, arm_trace = model.get_trace()\n",
      "\n",
      "    \u001b[37m# save result,format date\u001b[39;49;00m\n",
      "    pd.DataFrame(array([avg_rating, impressions]).T, columns=[\u001b[33m'\u001b[39;49;00m\u001b[33mrating\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mimpressions\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]) \\\n",
      "        .to_csv(\u001b[33m'\u001b[39;49;00m\u001b[33mtest_results/ictr32_results_\u001b[39;49;00m\u001b[33m{date}\u001b[39;49;00m\u001b[33m.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(date=date.today()))\n",
      "    \u001b[37m# save trace\u001b[39;49;00m\n",
      "    pd.DataFrame(array([reward_trace, arm_trace]), columns=[\u001b[33m'\u001b[39;49;00m\u001b[33mtrace\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]) \\\n",
      "        .to_csv(\u001b[33m'\u001b[39;49;00m\u001b[33mtest_results/ictr32_trace_\u001b[39;49;00m\u001b[33m{date}\u001b[39;49;00m\u001b[33m.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(date=date.today()))\n"
     ]
    }
   ],
   "source": [
    "! pygmentize docker/ICTR.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d581d161",
   "metadata": {},
   "source": [
    "# Create a Docker image, build the Docker training container, and push to Amazon ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ca6c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "ecr_repository = \"turbo-recommender-system\"\n",
    "tag = \":latest\"\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "uri_suffix = \"amazonaws.com\"\n",
    "if region in [\"cn-north-1\", \"cn-northwest-1\"]:\n",
    "    uri_suffix = \"amazonaws.com.cn\"\n",
    "image_uri = \"{}.dkr.ecr.{}.{}/{}\".format(account_id, region, uri_suffix, ecr_repository + tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0517aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'577361534221.dkr.ecr.us-east-1.amazonaws.com/turbo-recommender-system:latest'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c15a48b",
   "metadata": {},
   "source": [
    "# Build the Docker container and push it to Amazon ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087fe44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -t $ecr_repository docker\n",
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)\n",
    "!aws ecr create-repository --repository-name $ecr_repository\n",
    "!docker tag {ecr_repository + tag} $byoc_image_uri\n",
    "!docker push $byoc_image_uri"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
